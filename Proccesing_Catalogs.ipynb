{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a72e52-e89c-452a-9242-fa499d3b3718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c374b75-92c5-4b75-8b10-dee2fb359dbb",
   "metadata": {},
   "source": [
    "# **1. Imports and load NMDB data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb0605db-4426-485c-901c-fad0cc0ccdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MXCO</th>\n",
       "      <th>JUNG1</th>\n",
       "      <th>LMKS</th>\n",
       "      <th>NEWK</th>\n",
       "      <th>KERG</th>\n",
       "      <th>OULU</th>\n",
       "      <th>DOMC</th>\n",
       "      <th>INVK</th>\n",
       "      <th>APTY</th>\n",
       "      <th>AATB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>231.000</td>\n",
       "      <td>375.029</td>\n",
       "      <td>474.079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234.337</td>\n",
       "      <td>111.260</td>\n",
       "      <td>20.289</td>\n",
       "      <td>196.15</td>\n",
       "      <td>179.579</td>\n",
       "      <td>1416.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:02:00</th>\n",
       "      <td>233.000</td>\n",
       "      <td>375.602</td>\n",
       "      <td>475.306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>233.188</td>\n",
       "      <td>107.716</td>\n",
       "      <td>21.116</td>\n",
       "      <td>196.88</td>\n",
       "      <td>178.488</td>\n",
       "      <td>1424.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:04:00</th>\n",
       "      <td>232.250</td>\n",
       "      <td>372.678</td>\n",
       "      <td>474.119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>233.306</td>\n",
       "      <td>110.502</td>\n",
       "      <td>20.536</td>\n",
       "      <td>196.99</td>\n",
       "      <td>178.687</td>\n",
       "      <td>1436.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:06:00</th>\n",
       "      <td>228.417</td>\n",
       "      <td>364.417</td>\n",
       "      <td>472.085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234.694</td>\n",
       "      <td>109.483</td>\n",
       "      <td>20.876</td>\n",
       "      <td>197.58</td>\n",
       "      <td>179.851</td>\n",
       "      <td>1415.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:08:00</th>\n",
       "      <td>227.500</td>\n",
       "      <td>365.883</td>\n",
       "      <td>474.529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234.920</td>\n",
       "      <td>110.824</td>\n",
       "      <td>20.992</td>\n",
       "      <td>199.17</td>\n",
       "      <td>175.817</td>\n",
       "      <td>1427.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        MXCO    JUNG1     LMKS  NEWK     KERG     OULU  \\\n",
       "DATETIME                                                                 \n",
       "2018-01-01 00:00:00  231.000  375.029  474.079   NaN  234.337  111.260   \n",
       "2018-01-01 00:02:00  233.000  375.602  475.306   NaN  233.188  107.716   \n",
       "2018-01-01 00:04:00  232.250  372.678  474.119   NaN  233.306  110.502   \n",
       "2018-01-01 00:06:00  228.417  364.417  472.085   NaN  234.694  109.483   \n",
       "2018-01-01 00:08:00  227.500  365.883  474.529   NaN  234.920  110.824   \n",
       "\n",
       "                       DOMC    INVK     APTY     AATB  \n",
       "DATETIME                                               \n",
       "2018-01-01 00:00:00  20.289  196.15  179.579  1416.45  \n",
       "2018-01-01 00:02:00  21.116  196.88  178.488  1424.00  \n",
       "2018-01-01 00:04:00  20.536  196.99  178.687  1436.40  \n",
       "2018-01-01 00:06:00  20.876  197.58  179.851  1415.80  \n",
       "2018-01-01 00:08:00  20.992  199.17  175.817  1427.35  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load main NMDB dataset\n",
    "df = pd.read_csv(\"Results/DataStudy.csv\")\n",
    "# Parse datetime\n",
    "df[\"DATETIME\"] = pd.to_datetime(df[\"DATETIME\"])\n",
    "# Ensure timezone-naive index (if it was timezone-aware, drop tz; if not, this is harmless)\n",
    "try:\n",
    "    df[\"DATETIME\"] = df[\"DATETIME\"].dt.tz_convert(None)\n",
    "except TypeError:\n",
    "    # Already naive, nothing to do\n",
    "    pass\n",
    "df.set_index(\"DATETIME\", inplace=True)\n",
    "df = df.sort_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4223705-cd41-41d2-bc95-bbc572fd5332",
   "metadata": {},
   "source": [
    "# **2. Station list and basic time-step check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314f55e5-2e1d-45ec-b0fc-809894f7a687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx. time step: 2.00 minutes\n"
     ]
    }
   ],
   "source": [
    "# Stations to use in the Sierra method\n",
    "STATIONS = [\"MXCO\", \"JUNG1\", \"LMKS\", \"KERG\", \"OULU\", \"NEWK\", \"DOMC\", \"INVK\", \"APTY\", \"AATB\"]\n",
    "# Quick check: ensure all stations exist\n",
    "missing = [s for s in STATIONS if s not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing station columns in df: {missing}\")\n",
    "# Check approximate time step (in minutes)\n",
    "dt_minutes = (df.index[1] - df.index[0]).total_seconds() / 60.0\n",
    "print(f\"Approx. time step: {dt_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073dcd80-65c8-4316-b189-9e8526b83a9f",
   "metadata": {},
   "source": [
    "# **3. Core helper functions (deltaN + complexity + robust z)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f36e83c-1e6d-41e7-879c-2dfe27a0cef6",
   "metadata": {},
   "source": [
    "## **3.1 Background and deltaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b47e8d-ab86-41c3-b198-5082c37c544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_deltaN(df, station, bg_window_hours=72):\n",
    "    \"\"\"\n",
    "    Build a panel for one station with:\n",
    "      - counts\n",
    "      - counts_clean (spikes removed)\n",
    "      - bg (robust background via rolling median)\n",
    "      - deltaN (% deviation from bg)\n",
    "    \"\"\"\n",
    "    series = df[station].astype(float)\n",
    "\n",
    "    # Remove very large spikes (crude but safe)\n",
    "    med = series.median()\n",
    "    mad = (series - med).abs().median()\n",
    "    clean = series.mask((series - med).abs() > 6 * mad)\n",
    "\n",
    "    # Time step and background window\n",
    "    dt_minutes = (df.index[1] - df.index[0]).total_seconds() / 60.0\n",
    "    pts_per_hour = int(round(60.0 / dt_minutes))\n",
    "    bg_window = int(bg_window_hours * pts_per_hour)\n",
    "\n",
    "    bg = clean.rolling(window=bg_window,\n",
    "                       center=True,\n",
    "                       min_periods=int(0.5 * bg_window)).median()\n",
    "\n",
    "    deltaN = 100.0 * (clean - bg) / bg\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"counts\": series,\n",
    "        \"counts_clean\": clean,\n",
    "        \"bg\": bg,\n",
    "        \"deltaN\": deltaN\n",
    "    })\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e704ca-e489-4091-bef8-ab34106611a8",
   "metadata": {},
   "source": [
    "## **3.2 Complexity measures: permutation entropy and Katz FD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93c28981-d6e2-4568-860a-51544d010051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_entropy(x, m=3, delay=1):\n",
    "    \"\"\"\n",
    "    Normalized permutation entropy in [0, 1].\n",
    "    x: 1D array-like\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    n = len(x)\n",
    "    if n < m * delay:\n",
    "        return np.nan\n",
    "\n",
    "    patterns = []\n",
    "    for i in range(n - (m - 1) * delay):\n",
    "        window = x[i:i + m * delay:delay]\n",
    "        ranks = np.argsort(window)\n",
    "        patterns.append(tuple(ranks))\n",
    "\n",
    "    if len(patterns) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    patterns = np.array(patterns, dtype=object)\n",
    "    _, counts = np.unique(patterns, return_counts=True)\n",
    "    probs = counts / counts.sum()\n",
    "\n",
    "    pe = -np.sum(probs * np.log(probs))\n",
    "    pe_norm = pe / math.log(math.factorial(m))\n",
    "\n",
    "    return pe_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0334a88-86db-4c4d-8d3e-ff67c1561ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def katz_fd(x):\n",
    "    \"\"\"\n",
    "    Katz fractal dimension for a 1D series.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    n = len(x)\n",
    "    if n < 2:\n",
    "        return np.nan\n",
    "\n",
    "    diffs = np.diff(x)\n",
    "    L = np.sum(np.sqrt(1.0 + diffs**2))\n",
    "\n",
    "    t = np.arange(n, dtype=float)\n",
    "    dists = np.sqrt((t - t[0])**2 + (x - x[0])**2)\n",
    "    d = np.max(dists)\n",
    "\n",
    "    if d == 0 or L == 0:\n",
    "        return np.nan\n",
    "\n",
    "    return math.log10(n) / (math.log10(n) + math.log10(d / L))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ddcab-d3cd-48c8-9809-ae1f794412b5",
   "metadata": {},
   "source": [
    "## **3.3 Rolling complexity panel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11627dd4-4e6d-41db-a0e4-5c702c3ae9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_complexity_panel(st_df, window_hours=3, m=3, delay=1):\n",
    "    \"\"\"\n",
    "    Add PE and KFD in a sliding window over 'counts_clean'.\n",
    "    \"\"\"\n",
    "    dt_minutes = (st_df.index[1] - st_df.index[0]).total_seconds() / 60.0\n",
    "    pts_per_hour = int(round(60.0 / dt_minutes))\n",
    "    win = int(window_hours * pts_per_hour)\n",
    "\n",
    "    roll = st_df[\"counts_clean\"].rolling(window=win,\n",
    "                                         min_periods=int(0.5 * win))\n",
    "\n",
    "    pe = roll.apply(lambda x: permutation_entropy(x, m=m, delay=delay),\n",
    "                    raw=True)\n",
    "    kfd = roll.apply(lambda x: katz_fd(x),\n",
    "                     raw=True)\n",
    "\n",
    "    out = st_df.copy()\n",
    "    out[\"PE\"] = pe\n",
    "    out[\"KFD\"] = kfd\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c644178-b27f-4c39-94cf-80cf19165b92",
   "metadata": {},
   "source": [
    "## **3.4 Robust z-score and complexity anomaly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c545f2c1-6e3b-420b-a026-7da3260d5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_z(series, ref_mask):\n",
    "    \"\"\"\n",
    "    Robust z-score (median/MAD) over a reference subset.\n",
    "    \"\"\"\n",
    "    ref = series[ref_mask].dropna()\n",
    "    med = ref.median()\n",
    "    mad = (ref - med).abs().median()\n",
    "\n",
    "    if mad == 0 or np.isnan(mad):\n",
    "        return pd.Series(np.nan, index=series.index)\n",
    "\n",
    "    return (series - med) / mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8380718-7b6a-441f-95af-6172ee0d5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_complexity_scores(st_panel,\n",
    "                          quiet_start=\"2019-01-15\",\n",
    "                          quiet_end=\"2019-03-15\"):\n",
    "    \"\"\"\n",
    "    Add z_PE, z_KFD and A_complex to a station panel.\n",
    "    quiet_start/quiet_end define the reference quiet period.\n",
    "    \"\"\"\n",
    "    panel = st_panel.copy()\n",
    "    ref_mask = (panel.index >= quiet_start) & (panel.index < quiet_end)\n",
    "\n",
    "    panel[\"z_PE\"] = robust_z(panel[\"PE\"], ref_mask)\n",
    "    panel[\"z_KFD\"] = robust_z(panel[\"KFD\"], ref_mask)\n",
    "\n",
    "    panel[\"A_complex\"] = panel[[\"z_PE\", \"z_KFD\"]].abs().max(axis=1)\n",
    "\n",
    "    return panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c328dc-d27b-4ca0-b6cd-4b5242f6f609",
   "metadata": {},
   "source": [
    "# **4. Build per-station panels (deltaN + complexity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ee36df-a472-4b84-aac5-0b52b62bfb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building panel for MXCO ...\n",
      "Building panel for JUNG1 ...\n",
      "Building panel for LMKS ...\n",
      "Building panel for KERG ...\n",
      "Building panel for OULU ...\n",
      "Building panel for NEWK ...\n",
      "Building panel for DOMC ...\n",
      "Building panel for INVK ...\n",
      "Building panel for APTY ...\n",
      "Building panel for AATB ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>deltaN</th>\n",
       "      <th>PE</th>\n",
       "      <th>KFD</th>\n",
       "      <th>A_complex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>375.029</td>\n",
       "      <td>1.608955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:02:00</th>\n",
       "      <td>375.602</td>\n",
       "      <td>1.764339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:04:00</th>\n",
       "      <td>372.678</td>\n",
       "      <td>0.972668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:06:00</th>\n",
       "      <td>364.417</td>\n",
       "      <td>-1.265017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:08:00</th>\n",
       "      <td>365.883</td>\n",
       "      <td>-0.868357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      counts    deltaN  PE  KFD  A_complex\n",
       "DATETIME                                                  \n",
       "2018-01-01 00:00:00  375.029  1.608955 NaN  NaN        NaN\n",
       "2018-01-01 00:02:00  375.602  1.764339 NaN  NaN        NaN\n",
       "2018-01-01 00:04:00  372.678  0.972668 NaN  NaN        NaN\n",
       "2018-01-01 00:06:00  364.417 -1.265017 NaN  NaN        NaN\n",
       "2018-01-01 00:08:00  365.883 -0.868357 NaN  NaN        NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_panels = {}\n",
    "\n",
    "for st in STATIONS:\n",
    "    print(f\"Building panel for {st} ...\")\n",
    "    base = make_deltaN(df, st)\n",
    "    base = compute_complexity_panel(base, window_hours=3)\n",
    "    base = add_complexity_scores(base,\n",
    "                                 quiet_start=\"2019-01-15\",\n",
    "                                 quiet_end=\"2019-03-15\")\n",
    "    base[\"station_name\"] = st\n",
    "    station_panels[st] = base\n",
    "\n",
    "# Quick check\n",
    "station_panels[\"JUNG1\"][[\"counts\", \"deltaN\", \"PE\", \"KFD\", \"A_complex\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d93a3-295f-47ea-90d4-cc62b2db5999",
   "metadata": {},
   "source": [
    "# **5. Sierra FD detector (single station) and level definitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a472ab4e-a9be-4add-8ad7-59cb3db9f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fd_events(\n",
    "    station_df,\n",
    "    a_thresh=3.0,\n",
    "    min_a_duration_hours=3.0,\n",
    "    min_drop_percent=2.0,\n",
    "    max_time_to_min_hours=48.0,\n",
    "    recovery_fraction=0.5,\n",
    "    max_recovery_days=7.0,\n",
    "    bg_lookback_hours=24.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Sierra FD detector for a single station:\n",
    "      - station_df must have columns: deltaN, A_complex\n",
    "      - and a regular DateTimeIndex (naive or tz-aware).\n",
    "    \"\"\"\n",
    "    df = station_df.copy()\n",
    "\n",
    "    if \"deltaN\" not in df.columns or \"A_complex\" not in df.columns:\n",
    "        raise ValueError(\"station_df must have 'deltaN' and 'A_complex'\")\n",
    "\n",
    "    dt_minutes = (df.index[1] - df.index[0]).total_seconds() / 60.0\n",
    "    pts_per_hour = max(int(round(60.0 / dt_minutes)), 1)\n",
    "\n",
    "    min_a_pts        = int(round(min_a_duration_hours * pts_per_hour))\n",
    "    max_to_min_pts   = int(round(max_time_to_min_hours * pts_per_hour))\n",
    "    max_recovery_pts = int(round(max_recovery_days * 24.0 * pts_per_hour))\n",
    "    bg_lookback_pts  = int(round(bg_lookback_hours * pts_per_hour))\n",
    "\n",
    "    high_a = df[\"A_complex\"] > a_thresh\n",
    "    events = []\n",
    "\n",
    "    if not high_a.any():\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"station\", \"onset_time\", \"min_time\", \"rec_time\",\n",
    "            \"drop_percent\", \"A_complex_max\", \"bg_level_pre\"\n",
    "        ])\n",
    "\n",
    "    idx = np.where(high_a.values)[0]\n",
    "\n",
    "    # group contiguous indices into segments\n",
    "    segments = []\n",
    "    start = idx[0]\n",
    "    prev = idx[0]\n",
    "    for i in idx[1:]:\n",
    "        if i == prev + 1:\n",
    "            prev = i\n",
    "        else:\n",
    "            segments.append((start, prev))\n",
    "            start = i\n",
    "            prev = i\n",
    "    segments.append((start, prev))\n",
    "\n",
    "    # station name\n",
    "    if \"station_name\" in df.columns:\n",
    "        station_name = str(df[\"station_name\"].iloc[0])\n",
    "    else:\n",
    "        station_name = \"unknown\"\n",
    "\n",
    "    for (s0, s1) in segments:\n",
    "        length = s1 - s0 + 1\n",
    "        if length < min_a_pts:\n",
    "            continue\n",
    "\n",
    "        onset_idx = s0\n",
    "\n",
    "        i_start_bg = max(0, onset_idx - bg_lookback_pts)\n",
    "        i_end_bg   = max(0, onset_idx - 1)\n",
    "        if i_end_bg <= i_start_bg:\n",
    "            continue\n",
    "\n",
    "        bg_deltaN = df[\"deltaN\"].iloc[i_start_bg:i_end_bg]\n",
    "        if bg_deltaN.dropna().empty:\n",
    "            continue\n",
    "\n",
    "        level_pre = bg_deltaN.median()\n",
    "\n",
    "        i_min_search_end = min(len(df) - 1, onset_idx + max_to_min_pts)\n",
    "        seg_deltaN = df[\"deltaN\"].iloc[onset_idx:i_min_search_end + 1]\n",
    "        if seg_deltaN.dropna().empty:\n",
    "            continue\n",
    "\n",
    "        i_local_min = seg_deltaN.idxmin()\n",
    "        j_min = df.index.get_loc(i_local_min)\n",
    "        min_val = df.loc[i_local_min, \"deltaN\"]\n",
    "        drop = level_pre - min_val\n",
    "\n",
    "        if drop < min_drop_percent:\n",
    "            continue\n",
    "\n",
    "        i_rec_start = j_min\n",
    "        i_rec_end = min(len(df) - 1, j_min + max_recovery_pts)\n",
    "        rec_seg = df[\"deltaN\"].iloc[i_rec_start:i_rec_end + 1]\n",
    "        if rec_seg.dropna().empty:\n",
    "            continue\n",
    "\n",
    "        target_level = level_pre - (1.0 - recovery_fraction) * drop\n",
    "        rec_mask = rec_seg >= target_level\n",
    "        if rec_mask.any():\n",
    "            rec_time = rec_seg.index[rec_mask.argmax()]\n",
    "        else:\n",
    "            rec_time = np.nan\n",
    "\n",
    "        a_max = df[\"A_complex\"].iloc[s0:s1 + 1].max()\n",
    "\n",
    "        events.append({\n",
    "            \"station\": station_name,\n",
    "            \"onset_time\": df.index[onset_idx],\n",
    "            \"min_time\": i_local_min,\n",
    "            \"rec_time\": rec_time,\n",
    "            \"drop_percent\": float(drop),\n",
    "            \"A_complex_max\": float(a_max),\n",
    "            \"bg_level_pre\": float(level_pre),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b2d9c16-edf2-4b97-a67a-036c8fd8fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIERRA_LEVELS = {\n",
    "    \"strict\": {\"a_thresh\": 3.0, \"min_drop_percent\": 2.0},\n",
    "    \"medium\": {\"a_thresh\": 2.0, \"min_drop_percent\": 1.5},\n",
    "    \"loose\":  {\"a_thresh\": 1.5, \"min_drop_percent\": 1.0},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188ac4b-3b45-4465-a859-7ebee1b6611c",
   "metadata": {},
   "source": [
    "# **6. Run Sierra detector for all stations and levels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afae1afd-74d9-4d49-a2d4-ba4318b3f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Sierra level: strict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/h_rtmhz56bd84hgb5_cp68fc0000gn/T/ipykernel_15657/2661864651.py:25: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if col in ev_all.columns and pd.api.types.is_datetime64tz_dtype(ev_all[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Sierra level: medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/h_rtmhz56bd84hgb5_cp68fc0000gn/T/ipykernel_15657/2661864651.py:25: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if col in ev_all.columns and pd.api.types.is_datetime64tz_dtype(ev_all[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Sierra level: loose\n",
      "strict: 1406 events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8n/h_rtmhz56bd84hgb5_cp68fc0000gn/T/ipykernel_15657/2661864651.py:25: DeprecationWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if col in ev_all.columns and pd.api.types.is_datetime64tz_dtype(ev_all[col]):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>onset_time</th>\n",
       "      <th>min_time</th>\n",
       "      <th>rec_time</th>\n",
       "      <th>drop_percent</th>\n",
       "      <th>A_complex_max</th>\n",
       "      <th>bg_level_pre</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-13 10:52:00</td>\n",
       "      <td>2018-01-15 07:28:00</td>\n",
       "      <td>2018-01-15 07:30:00</td>\n",
       "      <td>3.017396</td>\n",
       "      <td>5.828022</td>\n",
       "      <td>0.071706</td>\n",
       "      <td>strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-28 10:54:00</td>\n",
       "      <td>2018-01-30 03:04:00</td>\n",
       "      <td>2018-01-30 03:06:00</td>\n",
       "      <td>2.715966</td>\n",
       "      <td>5.470556</td>\n",
       "      <td>-0.000434</td>\n",
       "      <td>strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-03-20 06:54:00</td>\n",
       "      <td>2018-03-20 16:42:00</td>\n",
       "      <td>2018-03-20 16:44:00</td>\n",
       "      <td>3.957647</td>\n",
       "      <td>5.525199</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-04-16 18:08:00</td>\n",
       "      <td>2018-04-18 13:30:00</td>\n",
       "      <td>2018-04-18 13:32:00</td>\n",
       "      <td>3.932926</td>\n",
       "      <td>4.393013</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>strict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-04-25 02:20:00</td>\n",
       "      <td>2018-04-25 03:26:00</td>\n",
       "      <td>2018-04-25 03:28:00</td>\n",
       "      <td>3.288606</td>\n",
       "      <td>5.082601</td>\n",
       "      <td>-0.072858</td>\n",
       "      <td>strict</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station          onset_time            min_time            rec_time  \\\n",
       "0    MXCO 2018-01-13 10:52:00 2018-01-15 07:28:00 2018-01-15 07:30:00   \n",
       "1    MXCO 2018-01-28 10:54:00 2018-01-30 03:04:00 2018-01-30 03:06:00   \n",
       "2    MXCO 2018-03-20 06:54:00 2018-03-20 16:42:00 2018-03-20 16:44:00   \n",
       "3    MXCO 2018-04-16 18:08:00 2018-04-18 13:30:00 2018-04-18 13:32:00   \n",
       "4    MXCO 2018-04-25 02:20:00 2018-04-25 03:26:00 2018-04-25 03:28:00   \n",
       "\n",
       "   drop_percent  A_complex_max  bg_level_pre   level  \n",
       "0      3.017396       5.828022      0.071706  strict  \n",
       "1      2.715966       5.470556     -0.000434  strict  \n",
       "2      3.957647       5.525199      0.000428  strict  \n",
       "3      3.932926       4.393013     -0.000214  strict  \n",
       "4      3.288606       5.082601     -0.072858  strict  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medium: 8839 events\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>onset_time</th>\n",
       "      <th>min_time</th>\n",
       "      <th>rec_time</th>\n",
       "      <th>drop_percent</th>\n",
       "      <th>A_complex_max</th>\n",
       "      <th>bg_level_pre</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-06 22:48:00</td>\n",
       "      <td>2018-01-06 22:58:00</td>\n",
       "      <td>2018-01-06 23:00:00</td>\n",
       "      <td>6.148011</td>\n",
       "      <td>5.069751</td>\n",
       "      <td>0.036456</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-09 03:08:00</td>\n",
       "      <td>2018-01-10 01:48:00</td>\n",
       "      <td>2018-01-10 01:50:00</td>\n",
       "      <td>13.056328</td>\n",
       "      <td>4.242166</td>\n",
       "      <td>-0.144521</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-13 10:44:00</td>\n",
       "      <td>2018-01-15 07:28:00</td>\n",
       "      <td>2018-01-15 07:30:00</td>\n",
       "      <td>3.017396</td>\n",
       "      <td>5.828022</td>\n",
       "      <td>0.071706</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-28 09:52:00</td>\n",
       "      <td>2018-01-30 03:04:00</td>\n",
       "      <td>2018-01-30 03:06:00</td>\n",
       "      <td>2.716616</td>\n",
       "      <td>5.470556</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-29 05:28:00</td>\n",
       "      <td>2018-01-31 00:16:00</td>\n",
       "      <td>2018-01-31 00:18:00</td>\n",
       "      <td>3.369039</td>\n",
       "      <td>3.658180</td>\n",
       "      <td>0.035996</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station          onset_time            min_time            rec_time  \\\n",
       "0    MXCO 2018-01-06 22:48:00 2018-01-06 22:58:00 2018-01-06 23:00:00   \n",
       "1    MXCO 2018-01-09 03:08:00 2018-01-10 01:48:00 2018-01-10 01:50:00   \n",
       "2    MXCO 2018-01-13 10:44:00 2018-01-15 07:28:00 2018-01-15 07:30:00   \n",
       "3    MXCO 2018-01-28 09:52:00 2018-01-30 03:04:00 2018-01-30 03:06:00   \n",
       "4    MXCO 2018-01-29 05:28:00 2018-01-31 00:16:00 2018-01-31 00:18:00   \n",
       "\n",
       "   drop_percent  A_complex_max  bg_level_pre   level  \n",
       "0      6.148011       5.069751      0.036456  medium  \n",
       "1     13.056328       4.242166     -0.144521  medium  \n",
       "2      3.017396       5.828022      0.071706  medium  \n",
       "3      2.716616       5.470556      0.000217  medium  \n",
       "4      3.369039       3.658180      0.035996  medium  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loose: 18580 events\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>onset_time</th>\n",
       "      <th>min_time</th>\n",
       "      <th>rec_time</th>\n",
       "      <th>drop_percent</th>\n",
       "      <th>A_complex_max</th>\n",
       "      <th>bg_level_pre</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-04 17:44:00</td>\n",
       "      <td>2018-01-06 01:44:00</td>\n",
       "      <td>2018-01-06 01:48:00</td>\n",
       "      <td>6.773046</td>\n",
       "      <td>4.000969</td>\n",
       "      <td>-0.036641</td>\n",
       "      <td>loose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-06 00:36:00</td>\n",
       "      <td>2018-01-06 01:44:00</td>\n",
       "      <td>2018-01-06 01:48:00</td>\n",
       "      <td>6.736591</td>\n",
       "      <td>4.327187</td>\n",
       "      <td>-0.073096</td>\n",
       "      <td>loose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-06 22:28:00</td>\n",
       "      <td>2018-01-06 22:58:00</td>\n",
       "      <td>2018-01-06 23:00:00</td>\n",
       "      <td>6.148011</td>\n",
       "      <td>5.069751</td>\n",
       "      <td>0.036456</td>\n",
       "      <td>loose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-07 17:22:00</td>\n",
       "      <td>2018-01-09 04:08:00</td>\n",
       "      <td>2018-01-09 04:10:00</td>\n",
       "      <td>3.326986</td>\n",
       "      <td>4.522868</td>\n",
       "      <td>0.108460</td>\n",
       "      <td>loose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MXCO</td>\n",
       "      <td>2018-01-09 03:06:00</td>\n",
       "      <td>2018-01-10 01:48:00</td>\n",
       "      <td>2018-01-10 01:50:00</td>\n",
       "      <td>13.056328</td>\n",
       "      <td>4.242166</td>\n",
       "      <td>-0.144521</td>\n",
       "      <td>loose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station          onset_time            min_time            rec_time  \\\n",
       "0    MXCO 2018-01-04 17:44:00 2018-01-06 01:44:00 2018-01-06 01:48:00   \n",
       "1    MXCO 2018-01-06 00:36:00 2018-01-06 01:44:00 2018-01-06 01:48:00   \n",
       "2    MXCO 2018-01-06 22:28:00 2018-01-06 22:58:00 2018-01-06 23:00:00   \n",
       "3    MXCO 2018-01-07 17:22:00 2018-01-09 04:08:00 2018-01-09 04:10:00   \n",
       "4    MXCO 2018-01-09 03:06:00 2018-01-10 01:48:00 2018-01-10 01:50:00   \n",
       "\n",
       "   drop_percent  A_complex_max  bg_level_pre  level  \n",
       "0      6.773046       4.000969     -0.036641  loose  \n",
       "1      6.736591       4.327187     -0.073096  loose  \n",
       "2      6.148011       5.069751      0.036456  loose  \n",
       "3      3.326986       4.522868      0.108460  loose  \n",
       "4     13.056328       4.242166     -0.144521  loose  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "events_by_level = {}   # level_name -> DataFrame with all stations\n",
    "\n",
    "for level_name, params in SIERRA_LEVELS.items():\n",
    "    print(f\"\\nRunning Sierra level: {level_name}\")\n",
    "    all_events = []\n",
    "    for st, panel in station_panels.items():\n",
    "        ev = detect_fd_events(\n",
    "            panel,\n",
    "            a_thresh=params[\"a_thresh\"],\n",
    "            min_drop_percent=params[\"min_drop_percent\"]\n",
    "        )\n",
    "        ev[\"level\"] = level_name\n",
    "        all_events.append(ev)\n",
    "\n",
    "    if all_events:\n",
    "        ev_all = pd.concat(all_events, ignore_index=True)\n",
    "    else:\n",
    "        ev_all = pd.DataFrame(columns=[\n",
    "            \"station\", \"onset_time\", \"min_time\", \"rec_time\",\n",
    "            \"drop_percent\", \"A_complex_max\", \"bg_level_pre\", \"level\"\n",
    "        ])\n",
    "\n",
    "    # Ensure naive datetimes\n",
    "    for col in [\"onset_time\", \"min_time\", \"rec_time\"]:\n",
    "        if col in ev_all.columns and pd.api.types.is_datetime64tz_dtype(ev_all[col]):\n",
    "            ev_all[col] = ev_all[col].dt.tz_convert(None)\n",
    "\n",
    "    events_by_level[level_name] = ev_all\n",
    "\n",
    "# Quick check\n",
    "for lvl, ev in events_by_level.items():\n",
    "    print(f\"{lvl}: {len(ev)} events\")\n",
    "    display(ev.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a462a1-2da4-4bfd-8dd6-3d7325c0bee9",
   "metadata": {},
   "source": [
    "# **7. Build coincidence tables (multi-station groups) for each level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23488367-23dd-4a7b-94b3-0728387b474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_coincidence_table(events_df,\n",
    "                            time_col=\"min_time\",\n",
    "                            coincidence_window_hours=12):\n",
    "    \"\"\"\n",
    "    Group events from multiple stations into coincident FD candidates.\n",
    "    \"\"\"\n",
    "    if events_df.empty:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"repr_time\", \"n_stations\", \"stations\",\n",
    "            \"drop_mean\", \"drop_max\",\n",
    "            \"A_complex_mean\", \"A_complex_max\"\n",
    "        ])\n",
    "\n",
    "    ev = events_df.sort_values(time_col).reset_index(drop=True)\n",
    "    dt = pd.to_timedelta(coincidence_window_hours, unit=\"h\")\n",
    "\n",
    "    groups = []\n",
    "    current_group = [0]\n",
    "    current_ref_time = ev.loc[0, time_col]\n",
    "\n",
    "    for i in range(1, len(ev)):\n",
    "        t = ev.loc[i, time_col]\n",
    "        if abs(t - current_ref_time) <= dt:\n",
    "            current_group.append(i)\n",
    "            current_ref_time = ev.loc[current_group, time_col].median()\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [i]\n",
    "            current_ref_time = t\n",
    "    groups.append(current_group)\n",
    "\n",
    "    rows = []\n",
    "    for g in groups:\n",
    "        g_ev = ev.loc[g]\n",
    "        rows.append({\n",
    "            \"repr_time\": g_ev[time_col].median(),\n",
    "            \"n_stations\": g_ev[\"station\"].nunique(),\n",
    "            \"stations\": \",\".join(sorted(g_ev[\"station\"].unique())),\n",
    "            \"drop_mean\": g_ev[\"drop_percent\"].mean(),\n",
    "            \"drop_max\": g_ev[\"drop_percent\"].max(),\n",
    "            \"A_complex_mean\": g_ev[\"A_complex_max\"].mean(),\n",
    "            \"A_complex_max\": g_ev[\"A_complex_max\"].max(),\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(\"repr_time\").reset_index(drop=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94944bc3-c9c7-48c2-9d59-8a5585a1a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STRICT SIERRA — COINCIDENCE TABLE (919 events) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repr_time</th>\n",
       "      <th>n_stations</th>\n",
       "      <th>stations</th>\n",
       "      <th>drop_mean</th>\n",
       "      <th>drop_max</th>\n",
       "      <th>A_complex_mean</th>\n",
       "      <th>A_complex_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 15:48:00</td>\n",
       "      <td>1</td>\n",
       "      <td>INVK</td>\n",
       "      <td>4.077303</td>\n",
       "      <td>4.077303</td>\n",
       "      <td>5.525709</td>\n",
       "      <td>5.525709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02 19:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>JUNG1</td>\n",
       "      <td>4.764506</td>\n",
       "      <td>4.925805</td>\n",
       "      <td>6.694942</td>\n",
       "      <td>8.011326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04 16:48:00</td>\n",
       "      <td>1</td>\n",
       "      <td>JUNG1</td>\n",
       "      <td>3.167172</td>\n",
       "      <td>3.167172</td>\n",
       "      <td>6.417919</td>\n",
       "      <td>6.417919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-10 10:09:00</td>\n",
       "      <td>2</td>\n",
       "      <td>INVK,JUNG1</td>\n",
       "      <td>2.860242</td>\n",
       "      <td>3.329036</td>\n",
       "      <td>5.558226</td>\n",
       "      <td>6.310481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-12 12:04:00</td>\n",
       "      <td>1</td>\n",
       "      <td>APTY</td>\n",
       "      <td>3.209376</td>\n",
       "      <td>3.209376</td>\n",
       "      <td>6.366117</td>\n",
       "      <td>6.366117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            repr_time  n_stations    stations  drop_mean  drop_max  \\\n",
       "0 2018-01-01 15:48:00           1        INVK   4.077303  4.077303   \n",
       "1 2018-01-02 19:30:00           1       JUNG1   4.764506  4.925805   \n",
       "2 2018-01-04 16:48:00           1       JUNG1   3.167172  3.167172   \n",
       "3 2018-01-10 10:09:00           2  INVK,JUNG1   2.860242  3.329036   \n",
       "4 2018-01-12 12:04:00           1        APTY   3.209376  3.209376   \n",
       "\n",
       "   A_complex_mean  A_complex_max  \n",
       "0        5.525709       5.525709  \n",
       "1        6.694942       8.011326  \n",
       "2        6.417919       6.417919  \n",
       "3        5.558226       6.310481  \n",
       "4        6.366117       6.366117  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MEDIUM SIERRA — COINCIDENCE TABLE (2627 events) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repr_time</th>\n",
       "      <th>n_stations</th>\n",
       "      <th>stations</th>\n",
       "      <th>drop_mean</th>\n",
       "      <th>drop_max</th>\n",
       "      <th>A_complex_mean</th>\n",
       "      <th>A_complex_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 15:48:00</td>\n",
       "      <td>1</td>\n",
       "      <td>INVK</td>\n",
       "      <td>4.115380</td>\n",
       "      <td>4.115380</td>\n",
       "      <td>5.525709</td>\n",
       "      <td>5.525709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02 19:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>JUNG1,NEWK</td>\n",
       "      <td>4.457538</td>\n",
       "      <td>4.925805</td>\n",
       "      <td>6.161780</td>\n",
       "      <td>8.011326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03 20:24:00</td>\n",
       "      <td>1</td>\n",
       "      <td>LMKS</td>\n",
       "      <td>2.614254</td>\n",
       "      <td>2.614254</td>\n",
       "      <td>4.737728</td>\n",
       "      <td>4.737728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04 21:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>AATB,JUNG1</td>\n",
       "      <td>2.149605</td>\n",
       "      <td>2.256320</td>\n",
       "      <td>3.836984</td>\n",
       "      <td>3.943058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05 17:49:00</td>\n",
       "      <td>2</td>\n",
       "      <td>LMKS,NEWK</td>\n",
       "      <td>4.978914</td>\n",
       "      <td>6.494157</td>\n",
       "      <td>5.273755</td>\n",
       "      <td>5.966886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            repr_time  n_stations    stations  drop_mean  drop_max  \\\n",
       "0 2018-01-01 15:48:00           1        INVK   4.115380  4.115380   \n",
       "1 2018-01-02 19:30:00           2  JUNG1,NEWK   4.457538  4.925805   \n",
       "2 2018-01-03 20:24:00           1        LMKS   2.614254  2.614254   \n",
       "3 2018-01-04 21:30:00           2  AATB,JUNG1   2.149605  2.256320   \n",
       "4 2018-01-05 17:49:00           2   LMKS,NEWK   4.978914  6.494157   \n",
       "\n",
       "   A_complex_mean  A_complex_max  \n",
       "0        5.525709       5.525709  \n",
       "1        6.161780       8.011326  \n",
       "2        4.737728       4.737728  \n",
       "3        3.836984       3.943058  \n",
       "4        5.273755       5.966886  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LOOSE SIERRA — COINCIDENCE TABLE (2982 events) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repr_time</th>\n",
       "      <th>n_stations</th>\n",
       "      <th>stations</th>\n",
       "      <th>drop_mean</th>\n",
       "      <th>drop_max</th>\n",
       "      <th>A_complex_mean</th>\n",
       "      <th>A_complex_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 19:32:00</td>\n",
       "      <td>2</td>\n",
       "      <td>APTY,INVK</td>\n",
       "      <td>3.775539</td>\n",
       "      <td>4.133120</td>\n",
       "      <td>4.517049</td>\n",
       "      <td>5.525709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02 19:30:00</td>\n",
       "      <td>5</td>\n",
       "      <td>AATB,DOMC,JUNG1,NEWK,OULU</td>\n",
       "      <td>4.543193</td>\n",
       "      <td>6.865848</td>\n",
       "      <td>4.641459</td>\n",
       "      <td>8.011326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03 20:24:00</td>\n",
       "      <td>1</td>\n",
       "      <td>LMKS</td>\n",
       "      <td>2.614254</td>\n",
       "      <td>2.614254</td>\n",
       "      <td>4.737728</td>\n",
       "      <td>4.737728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04 19:28:00</td>\n",
       "      <td>5</td>\n",
       "      <td>AATB,DOMC,INVK,JUNG1,NEWK</td>\n",
       "      <td>4.482358</td>\n",
       "      <td>11.818695</td>\n",
       "      <td>3.653533</td>\n",
       "      <td>4.111074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05 22:49:00</td>\n",
       "      <td>5</td>\n",
       "      <td>AATB,INVK,LMKS,MXCO,NEWK</td>\n",
       "      <td>4.823260</td>\n",
       "      <td>6.773046</td>\n",
       "      <td>4.584648</td>\n",
       "      <td>5.966886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            repr_time  n_stations                   stations  drop_mean  \\\n",
       "0 2018-01-01 19:32:00           2                  APTY,INVK   3.775539   \n",
       "1 2018-01-02 19:30:00           5  AATB,DOMC,JUNG1,NEWK,OULU   4.543193   \n",
       "2 2018-01-03 20:24:00           1                       LMKS   2.614254   \n",
       "3 2018-01-04 19:28:00           5  AATB,DOMC,INVK,JUNG1,NEWK   4.482358   \n",
       "4 2018-01-05 22:49:00           5   AATB,INVK,LMKS,MXCO,NEWK   4.823260   \n",
       "\n",
       "    drop_max  A_complex_mean  A_complex_max  \n",
       "0   4.133120        4.517049       5.525709  \n",
       "1   6.865848        4.641459       8.011326  \n",
       "2   2.614254        4.737728       4.737728  \n",
       "3  11.818695        3.653533       4.111074  \n",
       "4   6.773046        4.584648       5.966886  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coincidence_by_level = {}\n",
    "\n",
    "for level_name, ev in events_by_level.items():\n",
    "    coinc = build_coincidence_table(ev,\n",
    "                                    time_col=\"min_time\",\n",
    "                                    coincidence_window_hours=12)\n",
    "    coincidence_by_level[level_name] = coinc\n",
    "    print(f\"\\n=== {level_name.upper()} SIERRA — COINCIDENCE TABLE ({len(coinc)} events) ===\")\n",
    "    display(coinc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3543b55-ffaf-48e2-8308-ff6f97bbab54",
   "metadata": {},
   "source": [
    "# **8. Summary per year and level (events + coincidences)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de2db434-8190-4780-aa19-6c270da78fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== STRICT SIERRA =====\n",
      "2018: events= 118 | coinc(all)= 89, <stations>=1.11, max=2 | coinc(≥2st)= 10, <stations>=2.00, max=2\n",
      "2019: events= 119 | coinc(all)= 90, <stations>=1.17, max=2 | coinc(≥2st)= 15, <stations>=2.00, max=2\n",
      "2020: events= 105 | coinc(all)= 85, <stations>=1.04, max=2 | coinc(≥2st)=  3, <stations>=2.00, max=2\n",
      "2021: events= 294 | coinc(all)=139, <stations>=1.19, max=3 | coinc(≥2st)= 24, <stations>=2.12, max=3\n",
      "2022: events= 146 | coinc(all)=107, <stations>=1.21, max=3 | coinc(≥2st)= 20, <stations>=2.10, max=3\n",
      "2023: events= 191 | coinc(all)=135, <stations>=1.20, max=3 | coinc(≥2st)= 22, <stations>=2.23, max=3\n",
      "2024: events= 240 | coinc(all)=156, <stations>=1.37, max=3 | coinc(≥2st)= 50, <stations>=2.16, max=3\n",
      "2025: events= 193 | coinc(all)=118, <stations>=1.35, max=3 | coinc(≥2st)= 31, <stations>=2.32, max=3\n",
      "\n",
      "===== MEDIUM SIERRA =====\n",
      "2018: events= 819 | coinc(all)=328, <stations>=2.01, max=6 | coinc(≥2st)=192, <stations>=2.72, max=6\n",
      "2019: events= 752 | coinc(all)=308, <stations>=1.94, max=6 | coinc(≥2st)=170, <stations>=2.69, max=6\n",
      "2020: events= 801 | coinc(all)=312, <stations>=2.01, max=6 | coinc(≥2st)=184, <stations>=2.71, max=6\n",
      "2021: events=1078 | coinc(all)=320, <stations>=2.25, max=6 | coinc(≥2st)=212, <stations>=2.89, max=6\n",
      "2022: events=1072 | coinc(all)=334, <stations>=2.28, max=6 | coinc(≥2st)=217, <stations>=2.97, max=6\n",
      "2023: events=1412 | coinc(all)=357, <stations>=2.65, max=8 | coinc(≥2st)=276, <stations>=3.13, max=8\n",
      "2024: events=1578 | coinc(all)=361, <stations>=2.84, max=8 | coinc(≥2st)=279, <stations>=3.38, max=8\n",
      "2025: events=1327 | coinc(all)=307, <stations>=2.81, max=8 | coinc(≥2st)=234, <stations>=3.37, max=8\n",
      "\n",
      "===== LOOSE SIERRA =====\n",
      "2018: events=1942 | coinc(all)=381, <stations>=3.40, max=9 | coinc(≥2st)=325, <stations>=3.82, max=9\n",
      "2019: events=1788 | coinc(all)=382, <stations>=3.14, max=9 | coinc(≥2st)=329, <stations>=3.49, max=9\n",
      "2020: events=1858 | coinc(all)=385, <stations>=3.20, max=8 | coinc(≥2st)=315, <stations>=3.69, max=8\n",
      "2021: events=2147 | coinc(all)=371, <stations>=3.48, max=9 | coinc(≥2st)=320, <stations>=3.88, max=9\n",
      "2022: events=2328 | coinc(all)=379, <stations>=3.62, max=9 | coinc(≥2st)=329, <stations>=4.02, max=9\n",
      "2023: events=2907 | coinc(all)=377, <stations>=4.17, max=10 | coinc(≥2st)=349, <stations>=4.42, max=10\n",
      "2024: events=3010 | coinc(all)=377, <stations>=4.24, max=10 | coinc(≥2st)=341, <stations>=4.58, max=10\n",
      "2025: events=2600 | coinc(all)=330, <stations>=4.23, max=9 | coinc(≥2st)=293, <stations>=4.64, max=9\n"
     ]
    }
   ],
   "source": [
    "for level_name, ev in events_by_level.items():\n",
    "    print(f\"\\n===== {level_name.upper()} SIERRA =====\")\n",
    "\n",
    "    if ev.empty:\n",
    "        print(\"No events.\\n\")\n",
    "        continue\n",
    "\n",
    "    ev = ev.copy()\n",
    "    ev[\"year\"] = ev[\"onset_time\"].dt.year\n",
    "    events_per_year = ev.groupby(\"year\").size()\n",
    "\n",
    "    coinc = coincidence_by_level.get(level_name, pd.DataFrame()).copy()\n",
    "    if not coinc.empty:\n",
    "        coinc[\"year\"] = coinc[\"repr_time\"].dt.year\n",
    "\n",
    "        coinc_all = coinc.groupby(\"year\").agg(\n",
    "            n_coinc_all=(\"repr_time\", \"size\"),\n",
    "            n_stations_mean_all=(\"n_stations\", \"mean\"),\n",
    "            n_stations_max_all=(\"n_stations\", \"max\"),\n",
    "        )\n",
    "\n",
    "        coinc_ge2 = coinc[coinc[\"n_stations\"] >= 2].groupby(\"year\").agg(\n",
    "            n_coinc_ge2=(\"repr_time\", \"size\"),\n",
    "            n_stations_mean_ge2=(\"n_stations\", \"mean\"),\n",
    "            n_stations_max_ge2=(\"n_stations\", \"max\"),\n",
    "        )\n",
    "    else:\n",
    "        coinc_all = pd.DataFrame()\n",
    "        coinc_ge2 = pd.DataFrame()\n",
    "\n",
    "    years = sorted(\n",
    "        events_per_year.index\n",
    "        .union(coinc_all.index)\n",
    "        .union(coinc_ge2.index)\n",
    "    )\n",
    "\n",
    "    for y in years:\n",
    "        n_ev = int(events_per_year.get(y, 0))\n",
    "\n",
    "        row_all = coinc_all.loc[y] if y in coinc_all.index else None\n",
    "        row_ge2 = coinc_ge2.loc[y] if y in coinc_ge2.index else None\n",
    "\n",
    "        n_all  = int(row_all[\"n_coinc_all\"]) if row_all is not None else 0\n",
    "        m_all  = row_all[\"n_stations_mean_all\"] if row_all is not None else float(\"nan\")\n",
    "        M_all  = int(row_all[\"n_stations_max_all\"]) if row_all is not None else 0\n",
    "\n",
    "        n_ge2  = int(row_ge2[\"n_coinc_ge2\"]) if row_ge2 is not None else 0\n",
    "        m_ge2  = row_ge2[\"n_stations_mean_ge2\"] if row_ge2 is not None else float(\"nan\")\n",
    "        M_ge2  = int(row_ge2[\"n_stations_max_ge2\"]) if row_ge2 is not None else 0\n",
    "\n",
    "        print(\n",
    "            f\"{y}: events={n_ev:4d} | \"\n",
    "            f\"coinc(all)={n_all:3d}, <stations>={m_all:4.2f}, max={M_all} | \"\n",
    "            f\"coinc(≥2st)={n_ge2:3d}, <stations>={m_ge2:4.2f}, max={M_ge2}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a52fb2-3a57-4f30-9dec-3cca07fbbaa7",
   "metadata": {},
   "source": [
    "# **9. Load IZMIRAN 2019 catalog and match to Sierra coincidences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04fcb27a-684e-4660-a97e-61c56495b207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date of event</th>\n",
       "      <th>MagnM</th>\n",
       "      <th>Axym</th>\n",
       "      <th>Azrange</th>\n",
       "      <th>TminM</th>\n",
       "      <th>DminM</th>\n",
       "      <th>OType</th>\n",
       "      <th>Bmax</th>\n",
       "      <th>Bzmin</th>\n",
       "      <th>Vmax</th>\n",
       "      <th>Dstmin</th>\n",
       "      <th>t_izmiran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.01.04 12:00:00</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>62</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>554.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>2019-01-04 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.01.10 14:00:00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.65</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2019-01-10 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.01.13 01:00:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2019-01-13 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019.01.13 23:00:00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>403.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2019-01-13 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019.01.15 11:00:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.57</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>417.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>2019-01-15 11:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date of event  MagnM  Axym  Azrange  TminM  DminM  OType  Bmax  \\\n",
       "0  2019.01.04 12:00:00    1.4  1.01     0.80     62  -0.19      9  11.4   \n",
       "1  2019.01.10 14:00:00    0.6  0.82     0.65     14  -0.23      9   7.3   \n",
       "2  2019.01.13 01:00:00    0.4  0.84     0.50     10  -0.15      9   3.4   \n",
       "3  2019.01.13 23:00:00    0.5  1.06     0.70      2  -0.27      9  10.2   \n",
       "4  2019.01.15 11:00:00    0.4  1.06     0.57     15  -0.19      9   7.7   \n",
       "\n",
       "   Bzmin   Vmax  Dstmin           t_izmiran  \n",
       "0   -7.1  554.0   -23.0 2019-01-04 12:00:00  \n",
       "1   -3.0  509.0    -9.0 2019-01-10 14:00:00  \n",
       "2   -2.0  366.0    -4.0 2019-01-13 01:00:00  \n",
       "3   -3.8  403.0    -2.0 2019-01-13 23:00:00  \n",
       "4   -2.6  417.0    -7.0 2019-01-15 11:00:00  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust path / delimiter to your file\n",
    "izm = pd.read_csv(\"izmiran2019.txt\", delimiter=\"\\t\")\n",
    "#### Source: http://spaceweather.izmiran.ru/eng/fds2019.html\n",
    "izm[\"t_izmiran\"] = pd.to_datetime(izm[\"Date of event\"],\n",
    "                                  format=\"%Y.%m.%d %H:%M:%S\")\n",
    "izm[\"t_izmiran\"] = izm[\"t_izmiran\"].dt.tz_localize(None)\n",
    "\n",
    "izm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0f7436b-1c6f-4e8d-a82b-bdf324dc2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_izmiran_to_sierra(izm_df,\n",
    "                            coincidence_by_level,\n",
    "                            tolerance_hours=24):\n",
    "    \"\"\"\n",
    "    For each Sierra level, match each IZMIRAN event (2019)\n",
    "    to the closest Sierra coincidence event within ±tolerance_hours.\n",
    "    \"\"\"\n",
    "    tol = pd.Timedelta(hours=tolerance_hours)\n",
    "    matches_by_level = {}\n",
    "    summary_rows = []\n",
    "\n",
    "    for level_name, coinc in coincidence_by_level.items():\n",
    "        coinc_2019 = coinc[coinc[\"repr_time\"].dt.year == 2019].copy()\n",
    "        if coinc_2019.empty:\n",
    "            matches_by_level[level_name] = pd.DataFrame()\n",
    "            summary_rows.append({\n",
    "                \"level\": level_name,\n",
    "                \"n_izmiran\": len(izm_df),\n",
    "                \"n_matched\": 0,\n",
    "                \"match_fraction\": 0.0,\n",
    "                \"dt_median_hours\": np.nan,\n",
    "                \"dt_mean_abs_hours\": np.nan,\n",
    "                \"stations_mean\": np.nan,\n",
    "                \"stations_max\": 0,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        rows = []\n",
    "        for i, r in izm_df.iterrows():\n",
    "            t0 = r[\"t_izmiran\"]\n",
    "            dt = coinc_2019[\"repr_time\"] - t0\n",
    "            dt_abs = dt.abs()\n",
    "\n",
    "            jmin = dt_abs.idxmin()\n",
    "            best_dt = dt.loc[jmin]\n",
    "            best_row = coinc_2019.loc[jmin]\n",
    "\n",
    "            if dt_abs.loc[jmin] <= tol:\n",
    "                matched = True\n",
    "                dt_hours = best_dt.total_seconds() / 3600.0\n",
    "                n_st = best_row[\"n_stations\"]\n",
    "                st_list = best_row[\"stations\"]\n",
    "                drop_mean = best_row[\"drop_mean\"]\n",
    "                amax = best_row[\"A_complex_max\"]\n",
    "            else:\n",
    "                matched = False\n",
    "                dt_hours = np.nan\n",
    "                n_st = np.nan\n",
    "                st_list = \"\"\n",
    "                drop_mean = np.nan\n",
    "                amax = np.nan\n",
    "\n",
    "            rows.append({\n",
    "                \"idx_izmiran\": i,\n",
    "                \"t_izmiran\": t0,\n",
    "                \"MagnM\": r.get(\"MagnM\", np.nan),\n",
    "                \"matched\": matched,\n",
    "                \"dt_hours\": dt_hours,\n",
    "                \"n_stations\": n_st,\n",
    "                \"stations\": st_list,\n",
    "                \"drop_mean\": drop_mean,\n",
    "                \"A_complex_max\": amax,\n",
    "            })\n",
    "\n",
    "        matches = pd.DataFrame(rows)\n",
    "\n",
    "        matched_mask = matches[\"matched\"]\n",
    "        n_matched = matched_mask.sum()\n",
    "        if n_matched > 0:\n",
    "            dt_median = matches.loc[matched_mask, \"dt_hours\"].median()\n",
    "            dt_mean_abs = matches.loc[matched_mask, \"dt_hours\"].abs().mean()\n",
    "            st_mean = matches.loc[matched_mask, \"n_stations\"].mean()\n",
    "            st_max = matches.loc[matched_mask, \"n_stations\"].max()\n",
    "        else:\n",
    "            dt_median = np.nan\n",
    "            dt_mean_abs = np.nan\n",
    "            st_mean = np.nan\n",
    "            st_max = 0\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"level\": level_name,\n",
    "            \"n_izmiran\": len(izm_df),\n",
    "            \"n_matched\": int(n_matched),\n",
    "            \"match_fraction\": n_matched / len(izm_df),\n",
    "            \"dt_median_hours\": dt_median,\n",
    "            \"dt_mean_abs_hours\": dt_mean_abs,\n",
    "            \"stations_mean\": st_mean,\n",
    "            \"stations_max\": st_max,\n",
    "        })\n",
    "\n",
    "        matches_by_level[level_name] = matches\n",
    "\n",
    "    summary_by_level = pd.DataFrame(summary_rows).set_index(\"level\")\n",
    "    return matches_by_level, summary_by_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f369d014-9dfc-4f67-9b65-3f3d06c15e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_izmiran</th>\n",
       "      <th>n_matched</th>\n",
       "      <th>match_fraction</th>\n",
       "      <th>dt_median_hours</th>\n",
       "      <th>dt_mean_abs_hours</th>\n",
       "      <th>stations_mean</th>\n",
       "      <th>stations_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>124</td>\n",
       "      <td>45</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>-0.516667</td>\n",
       "      <td>11.860000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>124</td>\n",
       "      <td>118</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>1.616667</td>\n",
       "      <td>8.309605</td>\n",
       "      <td>1.805085</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loose</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>6.716935</td>\n",
       "      <td>3.233871</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_izmiran  n_matched  match_fraction  dt_median_hours  \\\n",
       "level                                                           \n",
       "strict        124         45        0.362903        -0.516667   \n",
       "medium        124        118        0.951613         1.616667   \n",
       "loose         124        124        1.000000         0.716667   \n",
       "\n",
       "        dt_mean_abs_hours  stations_mean  stations_max  \n",
       "level                                                   \n",
       "strict          11.860000       1.111111           2.0  \n",
       "medium           8.309605       1.805085           6.0  \n",
       "loose            6.716935       3.233871           9.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_by_level, summary_by_level = match_izmiran_to_sierra(\n",
    "    izm_df=izm,\n",
    "    coincidence_by_level=coincidence_by_level,\n",
    "    tolerance_hours=24\n",
    ")\n",
    "\n",
    "summary_by_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f294f9b0-a530-4cbe-a67b-4c106501c573",
   "metadata": {},
   "source": [
    "# **10. Sierra-M 2019 catalog (Medium + drop ≥ 1.5%) and quality classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8dd7fd71-f435-4f7e-8f28-1fe9f24178c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_coinc = coincidence_by_level[\"medium\"].copy()\n",
    "med_coinc[\"repr_time\"] = med_coinc[\"repr_time\"].dt.tz_localize(None)\n",
    "med_coinc_2019 = med_coinc[med_coinc[\"repr_time\"].dt.year == 2019].copy()\n",
    "\n",
    "# Sierra-M base catalog: drop_mean >= 1.5, at least 1 station\n",
    "sierra_M_2019 = med_coinc_2019[med_coinc_2019[\"drop_mean\"] >= 1.5].copy()\n",
    "len(sierra_M_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dcf61e8-5f65-4484-9b5c-213a099ffc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "C    136\n",
       "B     88\n",
       "A     82\n",
       "D      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_quality(row):\n",
    "    nst = row[\"n_stations\"]\n",
    "    drop = row[\"drop_mean\"]\n",
    "    if nst >= 3:\n",
    "        return \"A\"   # multi-station, most global\n",
    "    elif nst == 2:\n",
    "        return \"B\"   # bi-station\n",
    "    elif (nst == 1) and (drop >= 2.0):\n",
    "        return \"C\"   # local but strong\n",
    "    else:\n",
    "        return \"D\"   # weaker / marginal\n",
    "\n",
    "sierra_M_2019[\"quality\"] = sierra_M_2019.apply(assign_quality, axis=1)\n",
    "sierra_M_2019[\"quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6ef2797-5cfb-4b18-bbed-57ec8dac0ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sierra-only</th>\n",
       "      <th>Matched_IZMIRAN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>36</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>48</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sierra-only  Matched_IZMIRAN\n",
       "quality                              \n",
       "A                 43               39\n",
       "B                 36               52\n",
       "C                 48               88\n",
       "D                  0                2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flag which Sierra-M events have at least one IZMIRAN match (±24 h)\n",
    "tol = pd.Timedelta(hours=24)\n",
    "sierra_M_2019[\"matched_izmiran\"] = False\n",
    "\n",
    "for _, r in izm.iterrows():\n",
    "    t0 = r[\"t_izmiran\"]\n",
    "    mask = (sierra_M_2019[\"repr_time\"] >= t0 - tol) & \\\n",
    "           (sierra_M_2019[\"repr_time\"] <= t0 + tol)\n",
    "    sierra_M_2019.loc[mask, \"matched_izmiran\"] = True\n",
    "\n",
    "# Cross-tab quality vs matched / Sierra-only\n",
    "ct = pd.crosstab(sierra_M_2019[\"quality\"],\n",
    "                 sierra_M_2019[\"matched_izmiran\"])\n",
    "ct.columns = [\"Sierra-only\", \"Matched_IZMIRAN\"]\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a05b02b3-b799-4036-a26f-21806afe8367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IZMIRAN 2019: 124\n",
      "Captured by Sierra-M: 118 (0.952)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sierra_qualities\n",
       "C        38\n",
       "B,C      21\n",
       "B        16\n",
       "A        15\n",
       "A,C      14\n",
       "A,B      10\n",
       "A,B,C     2\n",
       "C,D       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also mark in IZMIRAN which ones are captured by Sierra-M and with what qualities\n",
    "flags = []\n",
    "quals = []\n",
    "\n",
    "for _, r in izm.iterrows():\n",
    "    t0 = r[\"t_izmiran\"]\n",
    "    mask = (sierra_M_2019[\"repr_time\"] >= t0 - tol) & \\\n",
    "           (sierra_M_2019[\"repr_time\"] <= t0 + tol)\n",
    "    if mask.any():\n",
    "        flags.append(True)\n",
    "        quals.append(\",\".join(sorted(sierra_M_2019.loc[mask, \"quality\"].unique())))\n",
    "    else:\n",
    "        flags.append(False)\n",
    "        quals.append(\"\")\n",
    "\n",
    "izm[\"in_sierra_M\"] = flags\n",
    "izm[\"sierra_qualities\"] = quals\n",
    "\n",
    "len_izm = len(izm)\n",
    "n_cap = izm[\"in_sierra_M\"].sum()\n",
    "\n",
    "print(\"Total IZMIRAN 2019:\", len_izm)\n",
    "print(\"Captured by Sierra-M:\", n_cap, f\"({n_cap/len_izm:.3f})\")\n",
    "\n",
    "izm[izm[\"in_sierra_M\"]][\"sierra_qualities\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8535e8db-883b-40ba-90ba-5eb0813d0ef7",
   "metadata": {},
   "source": [
    "# **11. Save catalogs to CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a935af0-0385-46c4-bf30-bd263687467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save per-level single-station events\n",
    "for lvl, ev in events_by_level.items():\n",
    "    ev.to_csv(f\"Results/sierra_events_{lvl}.csv\", index=False)\n",
    "\n",
    "# Save per-level coincidence tables\n",
    "for lvl, coinc in coincidence_by_level.items():\n",
    "    coinc.to_csv(f\"Results/sierra_coincidences_{lvl}.csv\", index=False)\n",
    "\n",
    "# Save Sierra-M 2019 catalog\n",
    "sierra_M_2019.to_csv(\"Results/sierra_M_2019_catalog.csv\", index=False)\n",
    "\n",
    "# Save IZMIRAN 2019 with flags\n",
    "izm.to_csv(\"Results/izmiran_2019_with_sierra_flags.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f7c95-80f0-41c7-a9c5-468daffd57a1",
   "metadata": {},
   "source": [
    "# **12. Build the AFTER-M catalog for all years**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6c23e40-29d1-4c16-8416-6b67caecf4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repr_time</th>\n",
       "      <th>n_stations</th>\n",
       "      <th>stations</th>\n",
       "      <th>drop_mean</th>\n",
       "      <th>drop_max</th>\n",
       "      <th>A_complex_mean</th>\n",
       "      <th>A_complex_max</th>\n",
       "      <th>year</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 15:48:00</td>\n",
       "      <td>1</td>\n",
       "      <td>INVK</td>\n",
       "      <td>4.115380</td>\n",
       "      <td>4.115380</td>\n",
       "      <td>5.525709</td>\n",
       "      <td>5.525709</td>\n",
       "      <td>2018</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02 19:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>JUNG1,NEWK</td>\n",
       "      <td>4.457538</td>\n",
       "      <td>4.925805</td>\n",
       "      <td>6.161780</td>\n",
       "      <td>8.011326</td>\n",
       "      <td>2018</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03 20:24:00</td>\n",
       "      <td>1</td>\n",
       "      <td>LMKS</td>\n",
       "      <td>2.614254</td>\n",
       "      <td>2.614254</td>\n",
       "      <td>4.737728</td>\n",
       "      <td>4.737728</td>\n",
       "      <td>2018</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04 21:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>AATB,JUNG1</td>\n",
       "      <td>2.149605</td>\n",
       "      <td>2.256320</td>\n",
       "      <td>3.836984</td>\n",
       "      <td>3.943058</td>\n",
       "      <td>2018</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05 17:49:00</td>\n",
       "      <td>2</td>\n",
       "      <td>LMKS,NEWK</td>\n",
       "      <td>4.978914</td>\n",
       "      <td>6.494157</td>\n",
       "      <td>5.273755</td>\n",
       "      <td>5.966886</td>\n",
       "      <td>2018</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            repr_time  n_stations    stations  drop_mean  drop_max  \\\n",
       "0 2018-01-01 15:48:00           1        INVK   4.115380  4.115380   \n",
       "1 2018-01-02 19:30:00           2  JUNG1,NEWK   4.457538  4.925805   \n",
       "2 2018-01-03 20:24:00           1        LMKS   2.614254  2.614254   \n",
       "3 2018-01-04 21:30:00           2  AATB,JUNG1   2.149605  2.256320   \n",
       "4 2018-01-05 17:49:00           2   LMKS,NEWK   4.978914  6.494157   \n",
       "\n",
       "   A_complex_mean  A_complex_max  year quality  \n",
       "0        5.525709       5.525709  2018       C  \n",
       "1        6.161780       8.011326  2018       B  \n",
       "2        4.737728       4.737728  2018       C  \n",
       "3        3.836984       3.943058  2018       B  \n",
       "4        5.273755       5.966886  2018       B  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# If not already loaded in this notebook:\n",
    "# coinc_medium = pd.read_csv(\"sierra_coincidences_medium.csv\", parse_dates=[\"repr_time\"])\n",
    "# if pd.api.types.is_datetime64tz_dtype(coinc_medium[\"repr_time\"]):\n",
    "#     coinc_medium[\"repr_time\"] = coinc_medium[\"repr_time\"].dt.tz_convert(None)\n",
    "\n",
    "# 1) Add year column\n",
    "coinc_M = med_coinc.copy()\n",
    "coinc_M[\"year\"] = coinc_M[\"repr_time\"].dt.year\n",
    "\n",
    "# 2) Apply AFTER-M amplitude selection: mean fractional decrease >= 1.5%\n",
    "mask_M = coinc_M[\"drop_mean\"] >= 1.5\n",
    "AFTER_M_all = coinc_M[mask_M].copy()\n",
    "\n",
    "# 3) Assign quality classes A/B/C/D (same logic as for 2019)\n",
    "conditions = [\n",
    "    AFTER_M_all[\"n_stations\"] >= 3,                                  # A\n",
    "    AFTER_M_all[\"n_stations\"] == 2,                                  # B\n",
    "    (AFTER_M_all[\"n_stations\"] == 1) & (AFTER_M_all[\"drop_mean\"] >= 2.0),  # C\n",
    "]\n",
    "choices = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "AFTER_M_all[\"quality\"] = np.select(conditions, choices, default=\"D\")\n",
    "\n",
    "# 4) Sort by time (optional but nice)\n",
    "AFTER_M_all = AFTER_M_all.sort_values(\"repr_time\").reset_index(drop=True)\n",
    "\n",
    "AFTER_M_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa3d653f-23ba-4a4c-ba15-13939d7dd1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 308)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AFTER_M_2019 = pd.read_csv(\"sierra_M_2019_catalog.csv\", parse_dates=[\"repr_time\"])\n",
    "AFTER_M_2019=sierra_M_2019.copy()\n",
    "\n",
    "AFTER_M_all_2019 = AFTER_M_all[AFTER_M_all[\"year\"] == 2019].copy()\n",
    "\n",
    "len(AFTER_M_all_2019), len(AFTER_M_2019)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3434f4d-f471-47ed-86cf-3dfb3bf2ebe8",
   "metadata": {},
   "source": [
    "# **13. Save the complete AFTER-M catalog (all years)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8637cbd-4bdb-4dbf-b177-3c07e723a497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved global AFTER-M catalog to Results/AFTER_M_full_catalog.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"Results\", exist_ok=True)\n",
    "\n",
    "AFTER_M_all.to_csv(\"Results/AFTER_M_full_catalog.csv\", index=False)\n",
    "print(\"Saved global AFTER-M catalog to Results/AFTER_M_full_catalog.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d57c7-c31e-4556-b3cd-5c073dc506ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
