{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e942cc-953a-4b36-b59d-2949d140ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMDB helper functions: download monthly / yearly neutron monitor data\n",
    "# in a robust way, directly into pandas DataFrames.\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from calendar import monthrange\n",
    "\n",
    "# Base URL for NMDB \"draw_graph\" interface\n",
    "BASE_URL = \"https://www.nmdb.eu/nest/draw_graph.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b801549-4d39-4560-bd0b-7209b201c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmdb_month_df(year, month, stations,\n",
    "                  dtype=\"corr_for_efficiency\",\n",
    "                  tresolution=2):\n",
    "    \"\"\"\n",
    "    Download one month of NMDB data and return a tidy pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    year : int\n",
    "        Year (e.g. 2000).\n",
    "    month : int\n",
    "        Month as integer 1–12.\n",
    "    stations : list of str\n",
    "        List of requested station codes, e.g.\n",
    "        [\"MXCO\", \"JUNG1\", \"LMKS\", \"NEWK\", \"KERG\", \"OULU\", \"THUL\", \"SOPO\"].\n",
    "    dtype : str, optional\n",
    "        NMDB data type, e.g. \"corr_for_efficiency\", \"count_rate\", etc.\n",
    "    tresolution : int, optional\n",
    "        Time resolution in minutes (as used by NMDB).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with columns:\n",
    "          - \"DATETIME\" (UTC timestamps)\n",
    "          - one column per station in `stations` (float, NaN where missing)\n",
    "\n",
    "        If a station is requested but not available for that month, the column\n",
    "        will be filled with NaNs for that month, but still present.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - NMDB sometimes returns only a subset of the requested stations for\n",
    "      a given time range. We detect which stations actually appear in the\n",
    "      header and then add empty columns for the missing ones, so the\n",
    "      column layout is consistent across months.\n",
    "    - Lines that do not look like data (e.g. header, comments, legal text)\n",
    "      are ignored.\n",
    "    \"\"\"\n",
    "\n",
    "    last_day = monthrange(year, month)[1]\n",
    "\n",
    "    # Parameters are essentially those encoded in the NMDB query URL\n",
    "    params = {\n",
    "        \"formchk\": 1,\n",
    "        \"stations[]\": stations,\n",
    "        \"tabchoice\": \"revori\",\n",
    "        \"dtype\": dtype,\n",
    "        \"tresolution\": tresolution,\n",
    "        \"force\": 1,\n",
    "        \"yunits\": 0,\n",
    "        \"date_choice\": \"bydate\",\n",
    "        \"start_day\": 1,\n",
    "        \"start_month\": month,\n",
    "        \"start_year\": year,\n",
    "        \"start_hour\": 0,\n",
    "        \"start_min\": 0,\n",
    "        \"end_day\": last_day,\n",
    "        \"end_month\": month,\n",
    "        \"end_year\": year,\n",
    "        \"end_hour\": 23,\n",
    "        \"end_min\": 59,\n",
    "        \"output\": \"ascii\",\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    response.raise_for_status()\n",
    "    lines = response.text.splitlines()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1) Detect the station header line.\n",
    "    #    It is a non-comment, non-empty line that appears just before the\n",
    "    #    actual data and does NOT start with a timestamp.\n",
    "    # ------------------------------------------------------------------\n",
    "    header_line = None\n",
    "    for ln in lines:\n",
    "        if ln.startswith(\"#\"):\n",
    "            continue\n",
    "        if not ln.strip():\n",
    "            continue\n",
    "        # If it's already a timestamp, we've reached the data block.\n",
    "        if re.match(r'^\\s*\\d{4}-\\d{2}-\\d{2}\\s', ln):\n",
    "            break\n",
    "        header_line = ln\n",
    "\n",
    "    if header_line is not None:\n",
    "        # Example: \"                       MXCO    KERG    OULU    SOPO\"\n",
    "        stations_in_file = header_line.split()\n",
    "    else:\n",
    "        # Fallback: assume all requested stations are present (rare case).\n",
    "        stations_in_file = stations\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2) Extract only the data lines, which start with \"YYYY-MM-DD ...\"\n",
    "    # ------------------------------------------------------------------\n",
    "    data_lines = [\n",
    "        ln for ln in lines\n",
    "        if re.match(r'^\\s*\\d{4}-\\d{2}-\\d{2}\\s', ln)\n",
    "    ]\n",
    "\n",
    "    if not data_lines:\n",
    "        raise ValueError(f\"No data lines found for {year}-{month:02d}. \"\n",
    "                         \"Check that the stations / dates are valid and NMDB has data.\")\n",
    "\n",
    "    # Columns as they appear in the file: DATETIME + stations_in_file\n",
    "    file_columns = [\"DATETIME\"] + stations_in_file\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3) Read into a DataFrame using only valid data lines\n",
    "    # ------------------------------------------------------------------\n",
    "    df = pd.read_csv(\n",
    "        StringIO(\"\\n\".join(data_lines)),\n",
    "        sep=\";\",\n",
    "        header=None,\n",
    "        names=file_columns,\n",
    "        na_values=[\"null\"],\n",
    "        on_bad_lines=\"skip\",  # ignore malformed lines instead of failing\n",
    "        engine=\"python\",\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 4) Parse timestamps and drop any rows where DATETIME is invalid\n",
    "    # ------------------------------------------------------------------\n",
    "    df[\"DATETIME\"] = pd.to_datetime(df[\"DATETIME\"].str.strip(),\n",
    "                                    errors=\"coerce\", utc=True)\n",
    "    df = df.dropna(subset=[\"DATETIME\"]).reset_index(drop=True)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 5) Add missing station columns (requested but not present in file)\n",
    "    # ------------------------------------------------------------------\n",
    "    for st in stations:\n",
    "        if st not in df.columns:\n",
    "            df[st] = pd.NA\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 6) Reorder columns: DATETIME + stations (in requested order)\n",
    "    # ------------------------------------------------------------------\n",
    "    ordered_cols = [\"DATETIME\"] + list(stations)\n",
    "    df = df[ordered_cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def nmdb_year_df(year, stations, dtype=\"corr_for_efficiency\", tresolution=2):\n",
    "    \"\"\"\n",
    "    Download a full year of NMDB data for a set of stations and return\n",
    "    a single concatenated DataFrame.\n",
    "\n",
    "    Months with no data (e.g., future months in the current year or\n",
    "    months where NMDB has no records for the requested stations) are\n",
    "    skipped gracefully.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    year : int\n",
    "        Year (e.g. 2000, 2018, 2025, etc.).\n",
    "    stations : list of str\n",
    "        Station list, e.g.\n",
    "        [\"MXCO\", \"JUNG1\", \"LMKS\", \"NEWK\", \"KERG\", \"OULU\", \"THUL\", \"SOPO\"].\n",
    "    dtype : str, optional\n",
    "        NMDB data type (passed to `nmdb_month_df`).\n",
    "    tresolution : int, optional\n",
    "        Time resolution in minutes (passed to `nmdb_month_df`).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_year : pandas.DataFrame\n",
    "        Concatenated DataFrame for the whole year (for the months that\n",
    "        actually have data), with columns:\n",
    "        \"DATETIME\" + stations (in the given order).\n",
    "    \"\"\"\n",
    "\n",
    "    monthly_dfs = []\n",
    "\n",
    "    for month in range(1, 13):\n",
    "        print(f\"Downloading {year}-{month:02d} ...\", flush=True)\n",
    "        try:\n",
    "            df_m = nmdb_month_df(\n",
    "                year=year,\n",
    "                month=month,\n",
    "                stations=stations,\n",
    "                dtype=dtype,\n",
    "                tresolution=tresolution,\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            # No data lines found for this month (e.g., future month)\n",
    "            print(f\"  -> Skipping {year}-{month:02d}: {e}\")\n",
    "            continue\n",
    "        except requests.HTTPError as e:\n",
    "            # HTTP error from NMDB (network issue, server error, etc.)\n",
    "            print(f\"  -> Skipping {year}-{month:02d} due to HTTP error: {e}\")\n",
    "            continue\n",
    "\n",
    "        if not df_m.empty:\n",
    "            monthly_dfs.append(df_m)\n",
    "        else:\n",
    "            print(f\"  -> Skipping {year}-{month:02d}: empty DataFrame returned.\")\n",
    "\n",
    "    if not monthly_dfs:\n",
    "        raise RuntimeError(\n",
    "            f\"No monthly data could be retrieved for year {year}. \"\n",
    "            \"Check the station list and the availability of NMDB data.\"\n",
    "        )\n",
    "\n",
    "    # Concatenate all available months\n",
    "    df_year = pd.concat(monthly_dfs, ignore_index=True)\n",
    "\n",
    "    # Sort chronologically and drop repeated timestamps (if any)\n",
    "    df_year = df_year.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "    df_year = df_year.drop_duplicates(subset=\"DATETIME\", keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "    return df_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ff1d1f-8a59-43fd-a800-804059b6a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [\"DOMB\",\"DOMC\",\"MRNY\",\"INVK\",\"APTY\",\"AATB\",\"AATA\",\"ROME\"]\n",
    "def get_all(year):\n",
    "    df = nmdb_year_df(year, stations)\n",
    "    # (opcional pero recomendable) ordenar por tiempo\n",
    "    df = df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "    # (opcional) revisar si hay duplicados en el tiempo\n",
    "    dups = df.duplicated(subset=\"DATETIME\").sum()\n",
    "    print(f\"Número de timestamps duplicados: {dups}\")\n",
    "    # (recomendado) eliminar duplicados por DATETIME, conservando la primera aparición\n",
    "    df = df.drop_duplicates(subset=\"DATETIME\", keep=\"first\").reset_index(drop=True)\n",
    "    # Guardar todo el año en un solo CSV\n",
    "    df.to_csv(\"Data2/nmdb_{}_all_stations.csv\".format(year), index=True)\n",
    "    print(\"Dataset para el año {} guardado exitosamente... DOne...!\".format(year))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1064c2ca-a702-45b6-8e7f-3c6f03854311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2018-01 ...\n",
      "Downloading 2018-02 ...\n",
      "Downloading 2018-03 ...\n",
      "Downloading 2018-04 ...\n",
      "Downloading 2018-05 ...\n",
      "Downloading 2018-06 ...\n",
      "Downloading 2018-07 ...\n",
      "Downloading 2018-08 ...\n",
      "Downloading 2018-09 ...\n",
      "Downloading 2018-10 ...\n",
      "Downloading 2018-11 ...\n",
      "Downloading 2018-12 ...\n",
      "Número de timestamps duplicados: 0\n",
      "Dataset para el año 2018 guardado exitosamente... DOne...!\n",
      "Downloading 2019-01 ...\n",
      "Downloading 2019-02 ...\n",
      "Downloading 2019-03 ...\n",
      "Downloading 2019-04 ...\n",
      "Downloading 2019-05 ...\n",
      "Downloading 2019-06 ...\n",
      "Downloading 2019-07 ...\n",
      "Downloading 2019-08 ...\n",
      "Downloading 2019-09 ...\n",
      "Downloading 2019-10 ...\n",
      "Downloading 2019-11 ...\n",
      "Downloading 2019-12 ...\n",
      "Número de timestamps duplicados: 0\n",
      "Dataset para el año 2019 guardado exitosamente... DOne...!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2018,2020,1):\n",
    "    get_all(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c530d-d463-42e1-af6d-fee06e6a50c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
